<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习三 | 霁月荒馆</title><meta name="keywords" content="machine learning,bayes decision"><meta name="author" content="Kino"><meta name="copyright" content="Kino"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. 朴素贝叶斯朴素贝叶斯的两个假设：  特征之间相互独立，即一个单词出现的可能性与它和其他单词相邻没有关系 每个特征同等重要">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习三">
<meta property="og:url" content="https://blog.xuwei.fun/2015/08/19/machineLearning03/index.html">
<meta property="og:site_name" content="霁月荒馆">
<meta property="og:description" content="1. 朴素贝叶斯朴素贝叶斯的两个假设：  特征之间相互独立，即一个单词出现的可能性与它和其他单词相邻没有关系 每个特征同等重要">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog.xuwei.fun/images/site/default_cover.jpg">
<meta property="article:published_time" content="2015-08-19T08:00:00.000Z">
<meta property="article:modified_time" content="2019-05-18T14:24:33.160Z">
<meta property="article:author" content="Kino">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="bayes decision">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.xuwei.fun/images/site/default_cover.jpg"><link rel="shortcut icon" href="/favicon.png"><link rel="canonical" href="https://blog.xuwei.fun/2015/08/19/machineLearning03/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="2B5sIuc3Rmb51DeqVwFAHtksp_EC3uubjUP1jf9bSRg"/><meta name="baidu-site-verification" content="hRzEYlh3gL"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-104049598-2"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-104049598-2');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":600},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":50,"languages":{"author":"Author: Kino","link":"Link: ","source":"Source: 霁月荒馆","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习三',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2019-05-18 22:24:33'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2.7.0/hint.min.css"><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="霁月荒馆" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/site/avatar.png" onerror="onerror=null;src='/images/site/404_error.png'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">123</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">122</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> Compass</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Amusement</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Image</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-feather-pointed"></i><span> Memo</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/thoughts/"><i class="fa-fw fa-solid fa-pencil"></i><span> Thoughts</span></a></li><li><a class="site-page child" href="/excerpt/"><i class="fa-fw fa-solid fa-paperclip"></i><span> Excerpt</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/sitemap.xml"><i class="fa-fw fa-solid fa-sitemap"></i><span> Sitemap</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">霁月荒馆</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> Compass</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Amusement</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Image</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa-solid fa-feather-pointed"></i><span> Memo</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/thoughts/"><i class="fa-fw fa-solid fa-pencil"></i><span> Thoughts</span></a></li><li><a class="site-page child" href="/excerpt/"><i class="fa-fw fa-solid fa-paperclip"></i><span> Excerpt</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/sitemap.xml"><i class="fa-fw fa-solid fa-sitemap"></i><span> Sitemap</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习三</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2015-08-19T08:00:00.000Z" title="Created 2015-08-19 16:00:00">2015-08-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2019-05-18T14:24:33.160Z" title="Updated 2019-05-18 22:24:33">2019-05-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/techonology/">techonology</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/techonology/ai/">ai</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>8min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习三"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2015/08/19/machineLearning03/#post-comment"><span class="gitalk-comment-count"></span></a></span></div></div></div><article class="post-content" id="article-container"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="1-朴素贝叶斯"><a href="#1-朴素贝叶斯" class="headerlink" title="1. 朴素贝叶斯"></a>1. 朴素贝叶斯</h3><p>朴素贝叶斯的两个假设：</p>
<ul>
<li>特征之间相互独立，即一个单词出现的可能性与它和其他单词相邻没有关系</li>
<li>每个特征同等重要</li>
</ul>
<span id="more"></span>
<h3 id="2-文本分类"><a href="#2-文本分类" class="headerlink" title="2. 文本分类"></a>2. 文本分类</h3><h4 id="2-1-准备数据"><a href="#2-1-准备数据" class="headerlink" title="2.1 准备数据"></a>2.1 准备数据</h4><p>从文本中构建词向量, 将文本看成单词向量或词条向量(也就是说将句子转换为向量)</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loadDataSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    postingList<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'my'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'has'</span><span class="token punctuation">,</span> <span class="token string">'flea'</span><span class="token punctuation">,</span> <span class="token string">'problems'</span><span class="token punctuation">,</span> <span class="token string">'help'</span><span class="token punctuation">,</span> <span class="token string">'please'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token string">'maybe'</span><span class="token punctuation">,</span> <span class="token string">'not'</span><span class="token punctuation">,</span> <span class="token string">'take'</span><span class="token punctuation">,</span> <span class="token string">'him'</span><span class="token punctuation">,</span> <span class="token string">'to'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'park'</span><span class="token punctuation">,</span> <span class="token string">'stupid'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token string">'my'</span><span class="token punctuation">,</span> <span class="token string">'dalmation'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'so'</span><span class="token punctuation">,</span> <span class="token string">'cute'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'love'</span><span class="token punctuation">,</span> <span class="token string">'him'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token string">'stop'</span><span class="token punctuation">,</span> <span class="token string">'posting'</span><span class="token punctuation">,</span> <span class="token string">'stupid'</span><span class="token punctuation">,</span> <span class="token string">'worthless'</span><span class="token punctuation">,</span> <span class="token string">'garbage'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token string">'mr'</span><span class="token punctuation">,</span> <span class="token string">'licks'</span><span class="token punctuation">,</span> <span class="token string">'ate'</span><span class="token punctuation">,</span> <span class="token string">'my'</span><span class="token punctuation">,</span> <span class="token string">'steak'</span><span class="token punctuation">,</span> <span class="token string">'how'</span><span class="token punctuation">,</span> <span class="token string">'to'</span><span class="token punctuation">,</span> <span class="token string">'stop'</span><span class="token punctuation">,</span> <span class="token string">'him'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token string">'quit'</span><span class="token punctuation">,</span> <span class="token string">'buying'</span><span class="token punctuation">,</span> <span class="token string">'worthless'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'food'</span><span class="token punctuation">,</span> <span class="token string">'stupid'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    classVec <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment">#1 is abusive, 0 not</span>
    <span class="token keyword">return</span> postingList<span class="token punctuation">,</span>classVec
                 
<span class="token keyword">def</span> <span class="token function">createVocabList</span><span class="token punctuation">(</span>dataSet<span class="token punctuation">)</span><span class="token punctuation">:</span>
    vocabSet <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">#create empty set</span>
    <span class="token keyword">for</span> document <span class="token keyword">in</span> dataSet<span class="token punctuation">:</span>
        vocabSet <span class="token operator">=</span> vocabSet <span class="token operator">|</span> <span class="token builtin">set</span><span class="token punctuation">(</span>document<span class="token punctuation">)</span> <span class="token comment">#union of the two sets</span>
    <span class="token keyword">return</span> <span class="token builtin">list</span><span class="token punctuation">(</span>vocabSet<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">setOfWords2Vec</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> inputSet<span class="token punctuation">)</span><span class="token punctuation">:</span>
    returnVec <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">)</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> inputSet<span class="token punctuation">:</span>
        <span class="token keyword">if</span> word <span class="token keyword">in</span> vocabList<span class="token punctuation">:</span>
            returnVec<span class="token punctuation">[</span>vocabList<span class="token punctuation">.</span>index<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span> <span class="token keyword">print</span> <span class="token string">"the word: %s is not in my Vocabulary!"</span> <span class="token operator">%</span> word
    <span class="token keyword">return</span> returnVec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>loadDataSet()创建了一些实验样本<br>createVocabList()会创建一个包含在所有文档中出现的不重复词的列表<br>获取词汇表后，使用setOfWords2Vec()函数，该函数的输入参数为词汇表及某个文档，输出的是文档向量，向量的每一元素为1或0，分别表示在词汇表中的单词在输入文档中是否出现</p>
<h4 id="2-2-训练算法"><a href="#2-2-训练算法" class="headerlink" title="2.2 训练算法"></a>2.2 训练算法</h4><p>从词向量计算概率</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">trainNB0</span><span class="token punctuation">(</span>trainMatrix<span class="token punctuation">,</span>trainCategory<span class="token punctuation">)</span><span class="token punctuation">:</span>
    numTrainDocs <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>trainMatrix<span class="token punctuation">)</span>
    numWords <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>trainMatrix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    pAbusive <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>trainCategory<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">float</span><span class="token punctuation">(</span>numTrainDocs<span class="token punctuation">)</span>
    p0Num <span class="token operator">=</span> ones<span class="token punctuation">(</span>numWords<span class="token punctuation">)</span><span class="token punctuation">;</span> p1Num <span class="token operator">=</span> ones<span class="token punctuation">(</span>numWords<span class="token punctuation">)</span>      <span class="token comment">#change to ones() </span>
    p0Denom <span class="token operator">=</span> <span class="token number">2.0</span><span class="token punctuation">;</span> p1Denom <span class="token operator">=</span> <span class="token number">2.0</span>                        <span class="token comment">#change to 2.0</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>numTrainDocs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> trainCategory<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            p1Num <span class="token operator">+=</span> trainMatrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            p1Denom <span class="token operator">+=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>trainMatrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            p0Num <span class="token operator">+=</span> trainMatrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            p0Denom <span class="token operator">+=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>trainMatrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    p1Vect <span class="token operator">=</span> log<span class="token punctuation">(</span>p1Num<span class="token operator">/</span>p1Denom<span class="token punctuation">)</span>          <span class="token comment">#change to log()</span>
    p0Vect <span class="token operator">=</span> log<span class="token punctuation">(</span>p0Num<span class="token operator">/</span>p0Denom<span class="token punctuation">)</span>          <span class="token comment">#change to log()</span>
    <span class="token keyword">return</span> p0Vect<span class="token punctuation">,</span>p1Vect<span class="token punctuation">,</span>pAbusive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上述训练算法原本应该为：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">p0Num <span class="token operator">=</span> zeros<span class="token punctuation">(</span>numWords<span class="token punctuation">)</span><span class="token punctuation">;</span> p1Num <span class="token operator">=</span> zeros<span class="token punctuation">(</span>numWords<span class="token punctuation">)</span>
p0Denom <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> p1Denom <span class="token operator">=</span> <span class="token number">0</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
p1Vect <span class="token operator">=</span> p1Num<span class="token operator">/</span>p1Denom
p0Vect <span class="token operator">=</span> p0Num<span class="token operator">/</span>p0Denom<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>原来初始化为0，使用zeros()，然而若其中一个概率值为0，则最终也为0，故改用ones()，并且同时修改p0(1)Denom为2<br>原来也没有对数，为了防止乘积数字太小下溢出为0，改用对数</p>
<p>代码函数中的输入参数为文档矩阵trainMatrix，以及由每篇文档类别标签所构成的向量trainCategory。首先计算文档属于侮辱性文档(class&#x3D;1)的概率，即P(1)，因为这是一个二分类问题较为简单，多于两类的分类问题要对代码稍作修改；之后计算条件概率；最后对每个元素除以该类别中的总词数</p>
<h4 id="2-3-测试算法"><a href="#2-3-测试算法" class="headerlink" title="2.3 测试算法"></a>2.3 测试算法</h4><p>根据现实情况修改分类器</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">classifyNB</span><span class="token punctuation">(</span>vec2Classify<span class="token punctuation">,</span> p0Vec<span class="token punctuation">,</span> p1Vec<span class="token punctuation">,</span> pClass1<span class="token punctuation">)</span><span class="token punctuation">:</span>
    p1 <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>vec2Classify <span class="token operator">*</span> p1Vec<span class="token punctuation">)</span> <span class="token operator">+</span> log<span class="token punctuation">(</span>pClass1<span class="token punctuation">)</span>    <span class="token comment">#element-wise mult</span>
    p0 <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>vec2Classify <span class="token operator">*</span> p0Vec<span class="token punctuation">)</span> <span class="token operator">+</span> log<span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> pClass1<span class="token punctuation">)</span>
    <span class="token keyword">if</span> p1 <span class="token operator">></span> p0<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> <span class="token number">0</span>

<span class="token keyword">def</span> <span class="token function">testingNB</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    listOPosts<span class="token punctuation">,</span>listClasses <span class="token operator">=</span> loadDataSet<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myVocabList <span class="token operator">=</span> createVocabList<span class="token punctuation">(</span>listOPosts<span class="token punctuation">)</span>
    trainMat<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> postinDoc <span class="token keyword">in</span> listOPosts<span class="token punctuation">:</span>
        trainMat<span class="token punctuation">.</span>append<span class="token punctuation">(</span>setOfWords2Vec<span class="token punctuation">(</span>myVocabList<span class="token punctuation">,</span> postinDoc<span class="token punctuation">)</span><span class="token punctuation">)</span>
    p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pAb <span class="token operator">=</span> trainNB0<span class="token punctuation">(</span>array<span class="token punctuation">(</span>trainMat<span class="token punctuation">)</span><span class="token punctuation">,</span>array<span class="token punctuation">(</span>listClasses<span class="token punctuation">)</span><span class="token punctuation">)</span>
    testEntry <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'love'</span><span class="token punctuation">,</span> <span class="token string">'my'</span><span class="token punctuation">,</span> <span class="token string">'dalmation'</span><span class="token punctuation">]</span>
    thisDoc <span class="token operator">=</span> array<span class="token punctuation">(</span>setOfWords2Vec<span class="token punctuation">(</span>myVocabList<span class="token punctuation">,</span> testEntry<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> testEntry<span class="token punctuation">,</span><span class="token string">'classified as: '</span><span class="token punctuation">,</span>classifyNB<span class="token punctuation">(</span>thisDoc<span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pAb<span class="token punctuation">)</span>
    testEntry <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'stupid'</span><span class="token punctuation">,</span> <span class="token string">'garbage'</span><span class="token punctuation">]</span>
    thisDoc <span class="token operator">=</span> array<span class="token punctuation">(</span>setOfWords2Vec<span class="token punctuation">(</span>myVocabList<span class="token punctuation">,</span> testEntry<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> testEntry<span class="token punctuation">,</span><span class="token string">'classified as: '</span><span class="token punctuation">,</span>classifyNB<span class="token punctuation">(</span>thisDoc<span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pAb<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用bayes.testingNB()测试算法。</p>
<h4 id="2-4-准备数据"><a href="#2-4-准备数据" class="headerlink" title="2.4 准备数据"></a>2.4 准备数据</h4><p>文档词袋模型: 我们将每个词的出现与否作为一个特征，这可以被描述为词集模型(set-of-words model)，如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为词袋模型(bag-of-words model)。在词袋中，每个单词可出现多次，而词集中每个词只能出现一次，为适应词袋模型，将setOfWords2Vec()函数稍作修改为bagOfWords2VecMN()</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">bagOfWords2VecMN</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> inputSet<span class="token punctuation">)</span><span class="token punctuation">:</span>
    returnVec <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">)</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> inputSet<span class="token punctuation">:</span>
        <span class="token keyword">if</span> word <span class="token keyword">in</span> vocabList<span class="token punctuation">:</span>
            returnVec<span class="token punctuation">[</span>vocabList<span class="token punctuation">.</span>index<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> returnVec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h3 id="3-过滤垃圾邮件"><a href="#3-过滤垃圾邮件" class="headerlink" title="3. 过滤垃圾邮件"></a>3. 过滤垃圾邮件</h3><h4 id="3-1-准备数据"><a href="#3-1-准备数据" class="headerlink" title="3.1 准备数据"></a>3.1 准备数据</h4><p>切分文本: 利用正则表达式切分文本</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">emailText <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'email/ham/6.txt'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> re
regExpress <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'\\w*'</span><span class="token punctuation">)</span>
listOfTokens <span class="token operator">=</span> regExpress<span class="token punctuation">.</span>split<span class="token punctuation">(</span>emailText<span class="token punctuation">)</span>
<span class="token punctuation">[</span>tok<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> tok <span class="token keyword">in</span> listOfTokens <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tok<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="3-2-测试算法"><a href="#3-2-测试算法" class="headerlink" title="3.2 测试算法"></a>3.2 测试算法</h4><p>使用朴素贝叶斯进行交叉验证</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">textParse</span><span class="token punctuation">(</span>bigString<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#input is big string, #output is word list</span>
    <span class="token keyword">import</span> re
    listOfTokens <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">r'\W*'</span><span class="token punctuation">,</span> bigString<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>tok<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> tok <span class="token keyword">in</span> listOfTokens <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tok<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">2</span><span class="token punctuation">]</span> 
    
<span class="token keyword">def</span> <span class="token function">spamTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    docList<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> classList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> fullText <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">26</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        wordList <span class="token operator">=</span> textParse<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'email/spam/%d.txt'</span> <span class="token operator">%</span> i<span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        docList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        fullText<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        classList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        wordList <span class="token operator">=</span> textParse<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'email/ham/%d.txt'</span> <span class="token operator">%</span> i<span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        docList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        fullText<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        classList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    vocabList <span class="token operator">=</span> createVocabList<span class="token punctuation">(</span>docList<span class="token punctuation">)</span><span class="token comment">#create vocabulary</span>
    trainingSet <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">;</span> testSet<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>           <span class="token comment">#create test set</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        randIndex <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>trainingSet<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        testSet<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trainingSet<span class="token punctuation">[</span>randIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">del</span><span class="token punctuation">(</span>trainingSet<span class="token punctuation">[</span>randIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>  
    trainMat<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> trainClasses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> docIndex <span class="token keyword">in</span> trainingSet<span class="token punctuation">:</span><span class="token comment">#train the classifier (get probs) trainNB0</span>
        trainMat<span class="token punctuation">.</span>append<span class="token punctuation">(</span>bagOfWords2VecMN<span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> docList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        trainClasses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>classList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
    p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pSpam <span class="token operator">=</span> trainNB0<span class="token punctuation">(</span>array<span class="token punctuation">(</span>trainMat<span class="token punctuation">)</span><span class="token punctuation">,</span>array<span class="token punctuation">(</span>trainClasses<span class="token punctuation">)</span><span class="token punctuation">)</span>
    errorCount <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> docIndex <span class="token keyword">in</span> testSet<span class="token punctuation">:</span>        <span class="token comment">#classify the remaining items</span>
        wordVector <span class="token operator">=</span> bagOfWords2VecMN<span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> docList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> classifyNB<span class="token punctuation">(</span>array<span class="token punctuation">(</span>wordVector<span class="token punctuation">)</span><span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pSpam<span class="token punctuation">)</span> <span class="token operator">!=</span> classList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">:</span>
            errorCount <span class="token operator">+=</span> <span class="token number">1</span>
            <span class="token keyword">print</span> <span class="token string">"classification error"</span><span class="token punctuation">,</span>docList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span>
    <span class="token keyword">print</span> <span class="token string">'the error rate is: '</span><span class="token punctuation">,</span><span class="token builtin">float</span><span class="token punctuation">(</span>errorCount<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>testSet<span class="token punctuation">)</span>
    <span class="token comment">#return vocabList,fullText</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>spamTest()对贝叶斯垃圾邮件分类器进行自动化处理，导入文件夹spam和ham下的文本文件，并将它们解析为词列表，接下来构建一个测试集和训练集，两个集合中的元素是被随机选出的。随机选取数据的一部分为训练集，而剩余部分作为测试集的过程称为*留存交叉验证(hold-out cross validation)*。重复多次求平均值可以更好的估计错误率</p>
<h3 id="4-示例"><a href="#4-示例" class="headerlink" title="4. 示例"></a>4. 示例</h3><p>使用朴素贝叶斯分类器从个人广告中获取区域倾向</p>
<h4 id="4-1-收集数据"><a href="#4-1-收集数据" class="headerlink" title="4.1 收集数据"></a>4.1 收集数据</h4><p>导入RSS源, 安装feedparser库<code>pip install feedparser</code>, 使用方法如下:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> feedparser
ny <span class="token operator">=</span> feedparser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">'http://newyork.craigslist.org/stp/index.rss'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> ny<span class="token punctuation">[</span><span class="token string">'entries'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>RSS源分类器及高频词去除函数</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calcMostFreq</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span>fullText<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> operator
    freqDict <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">for</span> token <span class="token keyword">in</span> vocabList<span class="token punctuation">:</span>
        freqDict<span class="token punctuation">[</span>token<span class="token punctuation">]</span><span class="token operator">=</span>fullText<span class="token punctuation">.</span>count<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
    sortedFreq <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>freqDict<span class="token punctuation">.</span>iteritems<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span>operator<span class="token punctuation">.</span>itemgetter<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> 
    <span class="token keyword">return</span> sortedFreq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">]</span>       

<span class="token keyword">def</span> <span class="token function">localWords</span><span class="token punctuation">(</span>feed1<span class="token punctuation">,</span>feed0<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> feedparser
    docList<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> classList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> fullText <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    minLen <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>feed1<span class="token punctuation">[</span><span class="token string">'entries'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>feed0<span class="token punctuation">[</span><span class="token string">'entries'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>minLen<span class="token punctuation">)</span><span class="token punctuation">:</span>
        wordList <span class="token operator">=</span> textParse<span class="token punctuation">(</span>feed1<span class="token punctuation">[</span><span class="token string">'entries'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'summary'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        docList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        fullText<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        classList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#NY is class 1</span>
        wordList <span class="token operator">=</span> textParse<span class="token punctuation">(</span>feed0<span class="token punctuation">[</span><span class="token string">'entries'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'summary'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        docList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        fullText<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>wordList<span class="token punctuation">)</span>
        classList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    vocabList <span class="token operator">=</span> createVocabList<span class="token punctuation">(</span>docList<span class="token punctuation">)</span><span class="token comment">#create vocabulary</span>
    top30Words <span class="token operator">=</span> calcMostFreq<span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span>fullText<span class="token punctuation">)</span>   <span class="token comment">#remove top 30 words</span>
    <span class="token keyword">for</span> pairW <span class="token keyword">in</span> top30Words<span class="token punctuation">:</span>
        <span class="token keyword">if</span> pairW<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> vocabList<span class="token punctuation">:</span> vocabList<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>pairW<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    trainingSet <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>minLen<span class="token punctuation">)</span><span class="token punctuation">;</span> testSet<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>           <span class="token comment">#create test set</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        randIndex <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>trainingSet<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        testSet<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trainingSet<span class="token punctuation">[</span>randIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">del</span><span class="token punctuation">(</span>trainingSet<span class="token punctuation">[</span>randIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>  
    trainMat<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> trainClasses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> docIndex <span class="token keyword">in</span> trainingSet<span class="token punctuation">:</span><span class="token comment">#train the classifier (get probs) trainNB0</span>
        trainMat<span class="token punctuation">.</span>append<span class="token punctuation">(</span>bagOfWords2VecMN<span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> docList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        trainClasses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>classList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
    p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pSpam <span class="token operator">=</span> trainNB0<span class="token punctuation">(</span>array<span class="token punctuation">(</span>trainMat<span class="token punctuation">)</span><span class="token punctuation">,</span>array<span class="token punctuation">(</span>trainClasses<span class="token punctuation">)</span><span class="token punctuation">)</span>
    errorCount <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> docIndex <span class="token keyword">in</span> testSet<span class="token punctuation">:</span>        <span class="token comment">#classify the remaining items</span>
        wordVector <span class="token operator">=</span> bagOfWords2VecMN<span class="token punctuation">(</span>vocabList<span class="token punctuation">,</span> docList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> classifyNB<span class="token punctuation">(</span>array<span class="token punctuation">(</span>wordVector<span class="token punctuation">)</span><span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span class="token punctuation">,</span>pSpam<span class="token punctuation">)</span> <span class="token operator">!=</span> classList<span class="token punctuation">[</span>docIndex<span class="token punctuation">]</span><span class="token punctuation">:</span>
            errorCount <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">print</span> <span class="token string">'the error rate is: '</span><span class="token punctuation">,</span><span class="token builtin">float</span><span class="token punctuation">(</span>errorCount<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>testSet<span class="token punctuation">)</span>
    <span class="token keyword">return</span> vocabList<span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>移除高频词是由于词汇表中的一小部分单词却占据了所有文本用词的一大部分，产生这种现象的原因是语言中大部分都是冗余和结构辅助性内容。另一个常用方法是不仅移除高频词，同时从某个预定词表中移除结构上的辅助词，该词表称为停用词表(stop word list)，可以在网上找到(例如 <a target="_blank" rel="noopener" href="http://www.ranks.nl/resources/stopwords.html">http://www.ranks.nl/resources/stopwords.html</a>)<br>通过以下命令测试上述代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">ny <span class="token operator">=</span> feedparser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">'http://newyork.craigslist.org/stp/index.rss'</span><span class="token punctuation">)</span>
sf <span class="token operator">=</span> feedparser<span class="token punctuation">.</span>parse<span class="token punctuation">(</span><span class="token string">'http://sfbay.craigslist.org/stp/index.rss'</span><span class="token punctuation">)</span>
vocabList<span class="token punctuation">,</span> pSF<span class="token punctuation">,</span> pNY <span class="token operator">=</span> bayes<span class="token punctuation">.</span>localWords<span class="token punctuation">(</span>ny<span class="token punctuation">,</span>sf<span class="token punctuation">)</span>
vocabList<span class="token punctuation">,</span> pSF<span class="token punctuation">,</span> pNY <span class="token operator">=</span> bayes<span class="token punctuation">.</span>localWords<span class="token punctuation">(</span>ny<span class="token punctuation">,</span>sf<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>为了得到错误率的精确估计，应该多次进行上述实验取平均值</p>
<h4 id="4-2-分析数据"><a href="#4-2-分析数据" class="headerlink" title="4.2 分析数据"></a>4.2 分析数据</h4><p>显示地域相关的用词, 可以先对向量pSF和pNY进行排序, 然后按照顺序将词打印出来。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">getTopWords</span><span class="token punctuation">(</span>ny<span class="token punctuation">,</span>sf<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> operator
    vocabList<span class="token punctuation">,</span>p0V<span class="token punctuation">,</span>p1V<span class="token operator">=</span>localWords<span class="token punctuation">(</span>ny<span class="token punctuation">,</span>sf<span class="token punctuation">)</span>
    topNY<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span> topSF<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>p0V<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> p0V<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> <span class="token operator">-</span><span class="token number">6.0</span> <span class="token punctuation">:</span> topSF<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>p0V<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> p1V<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> <span class="token operator">-</span><span class="token number">6.0</span> <span class="token punctuation">:</span> topNY<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>vocabList<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>p1V<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sortedSF <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>topSF<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> pair<span class="token punctuation">:</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token string">"SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**SF**"</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> sortedSF<span class="token punctuation">:</span>
        <span class="token keyword">print</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    sortedNY <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>topNY<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> pair<span class="token punctuation">:</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token string">"NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**"</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> sortedNY<span class="token punctuation">:</span>
        <span class="token keyword">print</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>getTopWords()使用两个RSS源作为输入，然后训练并测试朴素贝叶斯分类器，返回使用的概率值。<br><code>bayes.getTopWords(ny,sf)</code>可查看运行结果</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Kino</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://blog.xuwei.fun/2015/08/19/machineLearning03/">https://blog.xuwei.fun/2015/08/19/machineLearning03/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/machine-learning/">machine learning</a><a class="post-meta__tags" href="/tags/bayes-decision/">bayes decision</a></div><div class="post_share"><div class="social-share" data-image="/images/site/default_cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/site/qrcode_for_bitcoin.png" target="_blank"><img class="post-qr-code-img" src="/images/site/qrcode_for_bitcoin.png" alt="bitcoin"/></a><div class="post-qr-code-desc">bitcoin</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2015/08/25/machineLearning04/"><img class="prev-cover" src="/images/site/default_cover.jpg" onerror="onerror=null;src='/images/site/404_error.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">机器学习四</div></div></a></div><div class="next-post pull-right"><a href="/2015/08/17/patternRecognition02/"><img class="next-cover" src="/images/site/default_cover.jpg" onerror="onerror=null;src='/images/site/404_error.png'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">模式识别二</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2015/08/16/machineLearning02/" title="机器学习二"><img class="cover" src="/images/site/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2015-08-16</div><div class="title">机器学习二</div></div></a></div><div><a href="/2015/08/11/machineLearning01/" title="机器学习一"><img class="cover" src="/images/site/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2015-08-11</div><div class="title">机器学习一</div></div></a></div><div><a href="/2015/08/25/machineLearning04/" title="机器学习四"><img class="cover" src="/images/site/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2015-08-25</div><div class="title">机器学习四</div></div></a></div><div><a href="/2015/08/29/machineLearning05/" title="机器学习五"><img class="cover" src="/images/site/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2015-08-29</div><div class="title">机器学习五</div></div></a></div><div><a href="/2015/08/17/patternRecognition02/" title="模式识别二"><img class="cover" src="/images/site/default_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2015-08-17</div><div class="title">模式识别二</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Gitalk</span><span class="switch-btn"></span><span class="second-comment">Livere</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div><div><div id="lv-container" data-id="city" data-uid="MTAyMC8yOTkyNy82NDky"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/site/avatar.png" onerror="this.onerror=null;this.src='/images/site/404_error.png'" alt="avatar"/></div><div class="author-info__name">Kino</div><div class="author-info__description">Amor Fati</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">123</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">122</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/WoeiSheu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a><a class="social-icon" href="https://github.com/WoeiSheu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://twitter.com/KafuuKino" target="_blank" title="Twitter"><i class="fa-brands fa-twitter"></i></a><a class="social-icon" href="http://weibo.com/u/2613432527" target="_blank" title="Weibo"><i class="fa-brands fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">以今日之我与昨日之我战</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">1. 朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="toc-text">2. 文本分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-text">2.1 准备数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E8%AE%AD%E7%BB%83%E7%AE%97%E6%B3%95"><span class="toc-text">2.2 训练算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E6%B5%8B%E8%AF%95%E7%AE%97%E6%B3%95"><span class="toc-text">2.3 测试算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-text">2.4 准备数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%BF%87%E6%BB%A4%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6"><span class="toc-text">3. 过滤垃圾邮件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-text">3.1 准备数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E6%B5%8B%E8%AF%95%E7%AE%97%E6%B3%95"><span class="toc-text">3.2 测试算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%A4%BA%E4%BE%8B"><span class="toc-text">4. 示例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE"><span class="toc-text">4.1 收集数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE"><span class="toc-text">4.2 分析数据</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/08/derivatives05/" title="衍生品笔记五 —— 期货市场">衍生品笔记五 —— 期货市场</a><time datetime="2021-10-08T14:40:14.000Z" title="Created 2021-10-08 22:40:14">2021-10-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/07/derivatives04/" title="衍生品笔记四 —— 互换">衍生品笔记四 —— 互换</a><time datetime="2021-10-07T10:33:22.000Z" title="Created 2021-10-07 18:33:22">2021-10-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/06/derivatives03/" title="衍生品笔记三 —— 期货期权">衍生品笔记三 —— 期货期权</a><time datetime="2021-10-06T13:27:04.000Z" title="Created 2021-10-06 21:27:04">2021-10-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/04/derivatives02/" title="衍生品笔记二 —— 远期">衍生品笔记二 —— 远期</a><time datetime="2021-10-04T02:00:00.000Z" title="Created 2021-10-04 10:00:00">2021-10-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/03/derivatives01/" title="衍生品笔记一 —— 概述">衍生品笔记一 —— 概述</a><time datetime="2021-10-03T09:53:26.000Z" title="Created 2021-10-03 17:53:26">2021-10-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2012 - 2022 By Kino</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Sheu Woei</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Local search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '58ab17a966414cd66c67',
      clientSecret: '921b8d2afbcd56ea7f04bb0596fdb4d0306698c0',
      repo: 'WoeiSheu.github.io',
      owner: 'WoeiSheu',
      admin: ['WoeiSheu'],
      id: 'c6f425935c051b1536e7b9b7c70e9129',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Gitalk' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script></div><div class="aplayer no-destroy" data-id="5259076" data-server="netease" data-type="song" data-fixed="true" data-autoplay="false"> </div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'chat-with-kino/zen',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hint.css --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2.7.0/hint.min.css"></body></html>